{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Notes\n",
        "\n",
        "**Question**: *What's TF Model Garden.*\n",
        "\n",
        "**Aha**: A lib that allows you acess pre-build models, to adjust to your necessities.\n",
        "\n",
        "**URL**: https://www.tensorflow.org/tfmodels/nlp/fine_tune_bert"
      ],
      "metadata": {
        "id": "7ixXqWmVOxf9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code"
      ],
      "metadata": {
        "id": "rES3aP-aP0ZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!pip install -q opencv-python # why i need this?\n",
        "!pip install tensorflow-text\n",
        "!pip install -q tf-models-official"
      ],
      "metadata": {
        "id": "X7r5UzIyO31X"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "IpqXyTOiP1Ml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lib"
      ],
      "metadata": {
        "id": "4DWGjyr3P2Sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_models as tfm\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "tfds.disable_progress_bar()"
      ],
      "metadata": {
        "id": "J2qeiiTmP1y-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resources"
      ],
      "metadata": {
        "id": "zm_XzgVLP_qI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## this is how\n",
        "## we acess\n",
        "## Bert model\n",
        "\n",
        "gs_folder_bert = \"gs://cloud-tpu-checkpoints/bert/v3/uncased_L-12_H-768_A-12\"\n",
        "tf.io.gfile.listdir(gs_folder_bert)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gBt4Ay-QAG_",
        "outputId": "9ee41a0b-a9b9-4168-8bbf-07094f416b42"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bert_config.json',\n",
              " 'bert_model.ckpt.data-00000-of-00001',\n",
              " 'bert_model.ckpt.index',\n",
              " 'vocab.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and preprocess the dataset"
      ],
      "metadata": {
        "id": "7xUQwmucQFY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the dataset from TensorFlow Datasets"
      ],
      "metadata": {
        "id": "7qcHdnNfQHPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "glue, info = tfds.load('glue/mrpc',\n",
        "                       with_info=True,\n",
        "                       batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vwIxjaiQFlX",
        "outputId": "06015738-15e7-4c51-8479-d86fb65ff824"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 1.43 MiB (download: 1.43 MiB, generated: 1.74 MiB, total: 3.17 MiB) to /root/tensorflow_datasets/glue/mrpc/2.0.0...\n",
            "Dataset glue downloaded and prepared to /root/tensorflow_datasets/glue/mrpc/2.0.0. Subsequent calls will reuse this data.\n",
            "AttributeError: module 'ml_dtypes' has no attribute 'float4_e2m1fn'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(info.features)\n",
        "print('\\n')\n",
        "print(\"Classes:\")\n",
        "print(info.features['label'].names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amf7aXMYQLUe",
        "outputId": "75337ca7-adc3-4ac0-a0e3-f7ab4fc51c0f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FeaturesDict({\n",
            "    'idx': int32,\n",
            "    'label': ClassLabel(shape=(), dtype=int64, num_classes=2),\n",
            "    'sentence1': Text(shape=(), dtype=string),\n",
            "    'sentence2': Text(shape=(), dtype=string),\n",
            "})\n",
            "\n",
            "\n",
            "Classes:\n",
            "['not_equivalent', 'equivalent']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch = next(iter(glue['train']))\n",
        "\n",
        "for key, value in example_batch.items():\n",
        "  print(f\"{key:9s}: {value[0].numpy()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIzH3yXSQMnd",
        "outputId": "64bd70a9-4a02-4f68-be6f-5fc7737a5ecf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx      : 1680\n",
            "label    : 0\n",
            "sentence1: b'The identical rovers will act as robotic geologists , searching for evidence of past water .'\n",
            "sentence2: b'The rovers act as robotic geologists , moving on six wheels .'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process Data"
      ],
      "metadata": {
        "id": "WgafT7aHQPW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tfm.nlp.layers.FastWordpieceBertTokenizer(\n",
        "    vocab_file=os.path.join(gs_folder_bert, \"vocab.txt\"),\n",
        "    lower_case=True)"
      ],
      "metadata": {
        "id": "Uri1Dm0yQPim"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer(tf.constant([\"TensorFlow!\"]))\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8wemEWiQRz1",
        "outputId": "0c832bd0-39b0-455e-d208-ab1a7b18f245"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[[23435, 12314], [999]]]>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "special = tokenizer.get_special_tokens_dict()\n",
        "special"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "363o6w_nQR_W",
        "outputId": "9910bc0e-f3a4-4af8-f7e6-8e5f162768d3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vocab_size': 30522,\n",
              " 'start_of_sequence_id': 101,\n",
              " 'end_of_segment_id': 102,\n",
              " 'padding_id': 0,\n",
              " 'mask_id': 103}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length = 64\n",
        "\n",
        "packer = tfm.nlp.layers.BertPackInputs(\n",
        "    seq_length=max_seq_length,\n",
        "    special_tokens_dict = tokenizer.get_special_tokens_dict())"
      ],
      "metadata": {
        "id": "SpwNAWa4QTc2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences1 = [\"hello tensorflow\"]\n",
        "tok1 = tokenizer(sentences1)\n",
        "tok1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3Ps2-swQUkf",
        "outputId": "5dc38cd4-b0fc-4dca-d505-933b2f5e2331"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[[7592], [23435, 12314]]]>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences2 = [\"goodbye tensorflow\"]\n",
        "tok2 = tokenizer(sentences2)\n",
        "tok2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHUX1QZSQVm3",
        "outputId": "99996fdd-540e-418e-f65a-a62f9ce9228f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[[9119], [23435, 12314]]]>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "packed = packer([tok1, tok2])\n",
        "\n",
        "for key, tensor in packed.items():\n",
        "  print(f\"{key:15s}: {tensor[:, :12]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_qDVDQNQW6X",
        "outputId": "a6f5453c-2009-4687-9539-2e39ef1e4649"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_word_ids : [[  101  7592 23435 12314   102  9119 23435 12314   102     0     0     0]]\n",
            "input_mask     : [[1 1 1 1 1 1 1 1 1 0 0 0]]\n",
            "input_type_ids : [[0 0 0 0 0 1 1 1 1 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put All Together"
      ],
      "metadata": {
        "id": "8kno9dH_QZBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertInputProcessor(tf.keras.layers.Layer):\n",
        "  def __init__(self, tokenizer, packer):\n",
        "    super().__init__()\n",
        "    self.tokenizer = tokenizer\n",
        "    self.packer = packer\n",
        "\n",
        "  def call(self, inputs):\n",
        "    tok1 = self.tokenizer(inputs['sentence1'])\n",
        "    tok2 = self.tokenizer(inputs['sentence2'])\n",
        "\n",
        "    packed = self.packer([tok1, tok2])\n",
        "\n",
        "    if 'label' in inputs:\n",
        "      return packed, inputs['label']\n",
        "    else:\n",
        "      return packed"
      ],
      "metadata": {
        "id": "RVaROQ3sQX4m"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply to the dataset"
      ],
      "metadata": {
        "id": "a328tRorQcM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_inputs_processor = BertInputProcessor(tokenizer, packer)"
      ],
      "metadata": {
        "id": "J7GBOGGlQaiW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glue_train = glue['train'].map(bert_inputs_processor).prefetch(1)"
      ],
      "metadata": {
        "id": "FAk7e25kQf2t"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_inputs, example_labels = next(iter(glue_train))"
      ],
      "metadata": {
        "id": "2dkp6hRgQhbM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in example_inputs.items():\n",
        "  print(f'{key:15s} shape: {value.shape}')\n",
        "\n",
        "print(f'{\"labels\":15s} shape: {example_labels.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NecRWbr6Qitt",
        "outputId": "6e80101a-7d70-4167-8844-45f7930b9ad0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_word_ids  shape: (32, 64)\n",
            "input_mask      shape: (32, 64)\n",
            "input_type_ids  shape: (32, 64)\n",
            "labels          shape: (32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pcolormesh(example_inputs['input_word_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_mWYYPqQkPe",
        "outputId": "d9c3029b-d4f0-4b02-cf59-750df18d1db8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.QuadMesh at 0x7aed643b4f90>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pcolormesh(example_inputs['input_mask'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnPtC4nNQmKG",
        "outputId": "151485a5-5aff-42c2-abb4-4487e20c4e4e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.QuadMesh at 0x7aed60253190>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pcolormesh(example_inputs['input_type_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp_ZYT3NQoKN",
        "outputId": "04fd3e12-5b22-491e-928d-6ee2df640ea6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.QuadMesh at 0x7aed6022a4d0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glue_validation = glue['validation'].map(bert_inputs_processor).prefetch(1)\n",
        "glue_test = glue['test'].map(bert_inputs_processor).prefetch(1)"
      ],
      "metadata": {
        "id": "XGC7MBKrQpf1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build, train and export the model"
      ],
      "metadata": {
        "id": "4aeCBl6EQrYU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the model"
      ],
      "metadata": {
        "id": "g9S_-fG3Qs8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "bert_config_file = os.path.join(gs_folder_bert, \"bert_config.json\")\n",
        "config_dict = json.loads(tf.io.gfile.GFile(bert_config_file).read())\n",
        "config_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsxPj7bbQri9",
        "outputId": "30635ec1-b9c5-4fa8-d39e-b819c5baf583"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_probs_dropout_prob': 0.1,\n",
              " 'hidden_act': 'gelu',\n",
              " 'hidden_dropout_prob': 0.1,\n",
              " 'hidden_size': 768,\n",
              " 'initializer_range': 0.02,\n",
              " 'intermediate_size': 3072,\n",
              " 'max_position_embeddings': 512,\n",
              " 'num_attention_heads': 12,\n",
              " 'num_hidden_layers': 12,\n",
              " 'type_vocab_size': 2,\n",
              " 'vocab_size': 30522}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_config = tfm.nlp.encoders.EncoderConfig({\n",
        "    'type':'bert',\n",
        "    'bert': config_dict\n",
        "})"
      ],
      "metadata": {
        "id": "QI6XamHrQujN"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_encoder = tfm.nlp.encoders.build_encoder(encoder_config)\n",
        "bert_encoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkSc9Xh7Qv0V",
        "outputId": "eb1cded5-8292-4e86-d7dc-8cfa2d311e36"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<official.nlp.modeling.networks.bert_encoder.BertEncoder at 0x7aed53e33150>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_classifier = tfm.nlp.models.BertClassifier(network=bert_encoder, num_classes=2, )"
      ],
      "metadata": {
        "id": "u2n83H2HQw3N"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_classifier(example_inputs, training=True).numpy()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVSrP9erQxyX",
        "outputId": "ad70ef3d-9e4c-4a02-bfcd-66f8f3ac4030"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.5320878 ,  0.9695705 ],\n",
              "       [-0.4182374 ,  0.98895204],\n",
              "       [-0.36864024,  1.0823276 ],\n",
              "       [ 0.5420164 ,  0.9451803 ],\n",
              "       [-0.1331858 ,  0.9792325 ],\n",
              "       [-0.23708574,  0.5729923 ],\n",
              "       [ 0.28609204, -0.32386982],\n",
              "       [-0.23204884,  0.7961407 ],\n",
              "       [-0.5067148 ,  0.8174568 ],\n",
              "       [-0.33655012, -0.08161402]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(bert_encoder, show_shapes=True, dpi=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "mawzhc5wQyyG",
        "outputId": "a4b852fe-790e-4ec1-a5c9-0608bc450810"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADYAAAABCAIAAAAaWMqfAAAABmJLR0QA/wD/AP+gvaeTAAAANElEQVQImZXMsQ0AMQzDQNGAN/T+ixiQUnz/SFhdRWZGUhIAsF1VtoHd7W79BiS5x3d+wgHPfC3+LcIMKwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Restore Weights"
      ],
      "metadata": {
        "id": "47CKBbM1Q1ZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = tf.train.Checkpoint(encoder=bert_encoder)\n",
        "checkpoint.read(\n",
        "    os.path.join(gs_folder_bert, 'bert_model.ckpt')).assert_consumed()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQOJGjBzQz9m",
        "outputId": "ed5e6fe9-955f-40a6-8c5b-ce2b7b150caa"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7aed5adbf7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up and Optimazer"
      ],
      "metadata": {
        "id": "v_TDbi__Q4DU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up epochs and steps\n",
        "epochs = 2\n",
        "batch_size = 32\n",
        "eval_batch_size = 32\n",
        "\n",
        "train_data_size = info.splits['train'].num_examples\n",
        "steps_per_epoch = int(train_data_size / batch_size)\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "warmup_steps = int(0.1 * num_train_steps)\n",
        "initial_learning_rate=2e-5"
      ],
      "metadata": {
        "id": "tN1FR41XQ4OZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# linear_decay = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "#     initial_learning_rate=initial_learning_rate,\n",
        "#     end_learning_rate=0,\n",
        "#     decay_steps=num_train_steps)"
      ],
      "metadata": {
        "id": "IwsqYCtTQ6D4"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warmup_schedule = tfm.optimization.LinearWarmup(\n",
        "    warmup_learning_rate = 0,\n",
        "    after_warmup_lr_sched = 0,\n",
        "    warmup_steps = warmup_steps\n",
        ")"
      ],
      "metadata": {
        "id": "_D3jPQWGRLMM"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.linspace(0, num_train_steps, 1001)\n",
        "y = [warmup_schedule(xi) for xi in x]\n",
        "plt.plot(x,y)\n",
        "plt.xlabel('Train step')\n",
        "plt.ylabel('Learning rate')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mpYqxnPYeE0",
        "outputId": "831f2a20-6afe-4dec-b6a1-bbedafab1734"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(47.097222222222214, 0.5, 'Learning rate')"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.AdamW(\n",
        "    learning_rate = warmup_schedule)"
      ],
      "metadata": {
        "id": "AMy-E8AVaE0o"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy', dtype=tf.float32)]\n",
        "#loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "bert_classifier.compile(optimizer=optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "a1-UeqewarJf",
        "outputId": "5b4d9c28-22ee-48fe-f38a-9961c10283fd"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Could not interpret optimizer identifier: <keras.src.optimizers.adamw.AdamW object at 0x7aed512e2e50>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-6f71096e40d8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbert_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/optimizers/__init__.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m         )\n\u001b[1;32m    334\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    336\u001b[0m             \u001b[0;34mf\"Could not interpret optimizer identifier: {identifier}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Could not interpret optimizer identifier: <keras.src.optimizers.adamw.AdamW object at 0x7aed512e2e50>"
          ]
        }
      ]
    }
  ]
}